{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92ab716014374e4b",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-20T15:41:26.966359900Z",
     "start_time": "2024-08-20T15:41:26.958411600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "df_original = pd.read_csv(\"data/train_data.csv\")\n",
    "n_original = df_original.shape[0]\n",
    "df_submit = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df = pd.concat([df_original, df_submit], axis=0).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T15:41:27.399491Z",
     "start_time": "2024-08-20T15:41:26.961358900Z"
    }
   },
   "id": "321b9483bd4b86b3"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "\n",
    "# CNN模型定义\n",
    "class RegressionCNN(nn.Module):\n",
    "    def __init__(self, sequence_length):\n",
    "        super(RegressionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * ((sequence_length // 2) - 1), 100)  # Adjust size accordingly\n",
    "        self.regressor = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "\n",
    "# 特征构建函数（手工特征）\n",
    "def siRNA_feat_builder(s: pd.Series, anti: bool = False):\n",
    "    name = \"anti\" if anti else \"sense\"\n",
    "    df = s.to_frame()\n",
    "    df[f\"feat_siRNA_{name}_seq_len\"] = s.str.len()\n",
    "    for pos in [0, -1]:\n",
    "        for c in list(\"AUGC\"):\n",
    "            df[f\"feat_siRNA_{name}_seq_{c}_{'front' if pos == 0 else 'back'}\"] = (\n",
    "                s.str[pos] == c\n",
    "            )\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_1\"] = s.str.startswith(\"AA\") & s.str.endswith(\"UU\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_2\"] = s.str.startswith(\"GA\") & s.str.endswith(\"UU\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_3\"] = s.str.startswith(\"CA\") & s.str.endswith(\"UU\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_4\"] = s.str.startswith(\"UA\") & s.str.endswith(\"UU\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_5\"] = s.str.startswith(\"UU\") & s.str.endswith(\"AA\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_6\"] = s.str.startswith(\"UU\") & s.str.endswith(\"GA\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_7\"] = s.str.startswith(\"UU\") & s.str.endswith(\"CA\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_8\"] = s.str.startswith(\"UU\") & s.str.endswith(\"UA\")\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_9\"] = s.str[1] == \"A\"\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_10\"] = s.str[-2] == \"A\"\n",
    "    df[f\"feat_siRNA_{name}_seq_pattern_GC_frac\"] = (\n",
    "        s.str.contains(\"G\") + s.str.contains(\"C\")\n",
    "    ) / s.str.len()\n",
    "    return df.iloc[:, 1:]\n",
    "\n",
    "# 数据准备及特征构建\n",
    "df_publication_id = pd.get_dummies(df.publication_id)\n",
    "df_publication_id.columns = [f\"feat_publication_id_{c}\" for c in df_publication_id.columns]\n",
    "df_gene_target_symbol_name = pd.get_dummies(df.gene_target_symbol_name)\n",
    "df_gene_target_symbol_name.columns = [f\"feat_gene_target_symbol_name_{c}\" for c in df_gene_target_symbol_name.columns]\n",
    "df_gene_target_ncbi_id = pd.get_dummies(df.gene_target_ncbi_id)\n",
    "df_gene_target_ncbi_id.columns = [f\"feat_gene_target_ncbi_id_{c}\" for c in df_gene_target_ncbi_id.columns]\n",
    "df_gene_target_species = pd.get_dummies(df.gene_target_species)\n",
    "df_gene_target_species.columns = [f\"feat_gene_target_species_{c}\" for c in df_gene_target_species.columns]\n",
    "siRNA_duplex_id_values = df.siRNA_duplex_id.str.split(\"-|\\.\").str[1].astype(\"int\")\n",
    "siRNA_duplex_id_values = (siRNA_duplex_id_values - siRNA_duplex_id_values.min()) / (siRNA_duplex_id_values.max() - siRNA_duplex_id_values.min())\n",
    "df_siRNA_duplex_id = pd.DataFrame(siRNA_duplex_id_values)\n",
    "df_cell_line_donor = pd.get_dummies(df.cell_line_donor)\n",
    "df_cell_line_donor.columns = [f\"feat_cell_line_donor_{c}\" for c in df_cell_line_donor.columns]\n",
    "df_cell_line_donor[\"feat_cell_line_donor_hepatocytes\"] = (df.cell_line_donor.str.contains(\"Hepatocytes\")).fillna(False).astype(\"int\")\n",
    "df_cell_line_donor[\"feat_cell_line_donor_cells\"] = df.cell_line_donor.str.contains(\"Cells\").fillna(False).astype(\"int\")\n",
    "df_siRNA_concentration = df.siRNA_concentration.to_frame()\n",
    "df_Transfection_method = pd.get_dummies(df.Transfection_method)\n",
    "df_Transfection_method.columns = [f\"feat_Transfection_method_{c}\" for c in df_Transfection_method.columns]\n",
    "df_Duration_after_transfection_h = pd.get_dummies(df.Duration_after_transfection_h)\n",
    "df_Duration_after_transfection_h.columns = [f\"feat_Duration_after_transfection_h_{c}\" for c in df_Duration_after_transfection_h.columns]\n",
    "\n",
    "# 合并所有特征\n",
    "feats = pd.concat(\n",
    "    [\n",
    "        df_publication_id,\n",
    "        df_gene_target_symbol_name,\n",
    "        df_gene_target_ncbi_id,\n",
    "        df_gene_target_species,\n",
    "        df_siRNA_duplex_id,\n",
    "        df_cell_line_donor,\n",
    "        df_siRNA_concentration,\n",
    "        df_Transfection_method,\n",
    "        df_Duration_after_transfection_h,\n",
    "        siRNA_feat_builder(df.siRNA_sense_seq, False),\n",
    "        siRNA_feat_builder(df.siRNA_antisense_seq, True),\n",
    "        df.iloc[:, -1].to_frame(),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T15:41:27.878278400Z",
     "start_time": "2024-08-20T15:41:27.398490100Z"
    }
   },
   "id": "8f64e150d62cb1d1"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "X_seq_train 和 y_train 的样本数量不匹配！",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 30\u001B[0m\n\u001B[0;32m     27\u001B[0m X_seq_train, X_seq_test \u001B[38;5;241m=\u001B[39m train_test_split(X_seq, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# 确保X_seq_train和y_train的长度一致\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m X_seq_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m y_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_seq_train 和 y_train 的样本数量不匹配！\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# 创建数据集\u001B[39;00m\n\u001B[0;32m     33\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m TensorDataset(torch\u001B[38;5;241m.\u001B[39mtensor(X_seq_train, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32), torch\u001B[38;5;241m.\u001B[39mtensor(y_train\u001B[38;5;241m.\u001B[39mvalues, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32))\n",
      "\u001B[1;31mAssertionError\u001B[0m: X_seq_train 和 y_train 的样本数量不匹配！"
     ]
    }
   ],
   "source": [
    "\n",
    "# 数据划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feats.iloc[:n_original, :-1],\n",
    "    feats.iloc[:n_original, -1],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# 假定每个序列的固定长度\n",
    "sequence_length = 100\n",
    "\n",
    "# 整数编码函数\n",
    "def integer_encode_sequence(seq, sequence_length):\n",
    "    mapping = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
    "    # 截断序列\n",
    "    seq = seq[:sequence_length]\n",
    "    # 如果序列长度不足，填充到固定长度\n",
    "    if len(seq) < sequence_length:\n",
    "        seq += 'N' * (sequence_length - len(seq))\n",
    "    return np.array([mapping.get(base, 4) for base in seq])  # 4 表示未知或填充的碱基 'N'\n",
    "\n",
    "# 编码所有序列\n",
    "X_seq = np.array([integer_encode_sequence(seq, sequence_length) for seq in df['siRNA_antisense_seq']])\n",
    "X_seq = X_seq.reshape(X_seq.shape[0], 1, sequence_length)\n",
    "\n",
    "# 按照与X_train相同的方式划分X_seq\n",
    "X_seq_train, X_seq_test = train_test_split(X_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# 确保X_seq_train和y_train的长度一致\n",
    "assert X_seq_train.shape[0] == y_train.shape[0], \"X_seq_train 和 y_train 的样本数量不匹配！\"\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = TensorDataset(torch.tensor(X_seq_train, dtype=torch.float32), torch.tensor(y_train.values, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_seq_test, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义CNN模型、优化器和损失函数\n",
    "model = RegressionCNN(sequence_length)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 训练CNN模型\n",
    "def train_model(model, train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.view(-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 提取CNN特征\n",
    "def extract_features(model, loader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            output = model(data)\n",
    "            features.extend(output.view(-1).numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "# CNN模型训练与特征提取\n",
    "train_model(model, train_loader)\n",
    "X_train_features = extract_features(model, train_loader)\n",
    "X_test_features = extract_features(model, test_loader)\n",
    "\n",
    "# 将CNN特征加入到原始特征中\n",
    "X_train_combined = np.hstack([X_train, X_train_features.reshape(-1, 1)])\n",
    "X_test_combined = np.hstack([X_test, X_test_features.reshape(-1, 1)])\n",
    "\n",
    "# LightGBM模型训练与评估\n",
    "train_data = lgb.Dataset(X_train_combined, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_combined, label=y_test, reference=train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T15:41:28.131019500Z",
     "start_time": "2024-08-20T15:41:27.882279100Z"
    }
   },
   "id": "ee16190ff0ffa16b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(preds, data, threshold=30):\n",
    "    y_pred = preds\n",
    "    y_true = data.get_label()\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    y_true_binary = ((y_true <= threshold) & (y_true >= 0)).astype(int)\n",
    "    y_pred_binary = ((y_pred <= threshold) & (y_pred >= 0)).astype(int)\n",
    "\n",
    "    mask = (y_pred >= 0) & (y_pred <= threshold)\n",
    "    range_mae = mean_absolute_error(y_true[mask], y_pred[mask]) if np.sum(mask) > 0 else 100\n",
    "\n",
    "    precision = (np.array(y_pred_binary) & y_true_binary).sum() / np.sum(y_pred_binary) if np.sum(y_pred_binary) > 0 else 0\n",
    "    recall = (np.array(y_pred_binary) & y_true_binary).sum() / np.sum(y_true_binary) if np.sum(y_true_binary) > 0 else 0\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    score = (1 - mae / 100) * 0.5 + (1 - range_mae / 100) * f1 * 0.5\n",
    "    return \"custom_score\", score, True\n",
    "\n",
    "def adaptive_learning_rate(decay_rate=0.8, patience=50):\n",
    "    best_score = float(\"-inf\")\n",
    "    wait = 0\n",
    "\n",
    "    def callback(env):\n",
    "        nonlocal best_score, wait\n",
    "        current_score = env.evaluation_result_list[-1][2]\n",
    "        current_lr = env.model.params.get('learning_rate')\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait >= patience:\n",
    "            new_lr = float(current_lr) * decay_rate\n",
    "            wait = 0\n",
    "            env.model.params['learning_rate'] = new_lr\n",
    "            print(f\"Learning rate adjusted to {env.model.params.get('learning_rate')}\")\n",
    "\n",
    "    return callback\n",
    "\n",
    "def train(feats, n_original):\n",
    "    n_splits = 10\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    gbms = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(feats.iloc[:n_original, :]), 1):\n",
    "        print(f\"Starting fold {fold}\")\n",
    "        X_train, X_val = feats.iloc[train_idx, :-1], feats.iloc[val_idx, :-1]\n",
    "        y_train, y_val = feats.iloc[train_idx, -1], feats.iloc[val_idx, -1]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        params = {\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"None\",\n",
    "            \"max_depth\": 8,\n",
    "            \"num_leaves\": 63,\n",
    "            \"min_data_in_leaf\": 2,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"lambda_l1\": 0.1,\n",
    "            \"lambda_l2\": 0.2,\n",
    "            \"verbose\": -1,\n",
    "            \"num_threads\": 8,\n",
    "        }\n",
    "\n",
    "        adaptive_lr = adaptive_learning_rate(decay_rate=0.9, patience=1000)\n",
    "        gbm = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=25000,\n",
    "            valid_sets=[val_data],\n",
    "            feval=calculate_metrics,\n",
    "            callbacks=[\n",
    "                adaptive_lr,\n",
    "                lgb.log_evaluation(period=200, show_stdv=True),\n",
    "                lgb.early_stopping(stopping_rounds=int(25000*0.1), first_metric_only=True, verbose=True, min_delta=0.00001)\n",
    "            ]\n",
    "        )\n",
    "        valid_score = gbm.best_score[\"valid_0\"][\"custom_score\"]\n",
    "        print(f\"Fold {fold} best valid score: {valid_score}\")\n",
    "        gbms.append(gbm)\n",
    "\n",
    "    return gbms\n",
    "\n",
    "# 训练最终模型\n",
    "trained_gbms = train(feats, n_original)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T15:41:28.134020200Z",
     "start_time": "2024-08-20T15:41:28.132020300Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 预测并保存结果\n",
    "y_pred = np.mean([gbm.predict(feats.iloc[n_original:, :-1]) for gbm in trained_gbms], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-20T15:41:28.134020200Z"
    }
   },
   "id": "b47632f24f5cd0dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_submit[\"mRNA_remaining_pct\"] = y_pred\n",
    "df_submit.to_csv(\"submission.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-20T15:41:28.134020200Z"
    }
   },
   "id": "1f04187ed79a696a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
